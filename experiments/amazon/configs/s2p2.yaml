defaults:
  - default
  - _self_

name: s2p2
s2p2_num_layers: 4  # Default number of S2P2 layers
max_intensity: 4  # Match NHP: prevent single class from dominating.

head:
  use_batch_norm: false  # Cont-time models are worse with BN.
  hidden_dims: [64]  # EasyTPP IntensityNet: direct Linear projection, no hidden layers

module:
  _target_: hotpp.modules.NextItemModule
  seq_encoder:
    _target_: hotpp.nn.RnnEncoder
    embedder:
      _target_: hotpp.nn.Embedder
      embeddings:
        labels:
          in: ${num_classes}
          out: ${rnn_hidden_size}  # 128-dim, same as EasyTPP layers_mark_emb
      # NOTE: timestamps removed from embedder - S2P2 uses time_deltas separately
    rnn_partial:
      _target_: hotpp.nn.S2P2Encoder
      _partial_: true
      hidden_size: ${rnn_hidden_size}
      state_dim: 16  # P in EasyTPP
      num_layers: ${s2p2_num_layers}
      num_event_types: ${num_classes}
      dt_init_min: 0.0001
      dt_init_max: 0.1
      act_func: gelu
      dropout_rate: 0.1
      for_loop: true
      pre_norm: false
      post_norm: true
      simple_mark: true
      relative_time: false
      complex_values: true
      int_forward_variant: false
      int_backward_variant: true
    max_time_delta: ${max_time_delta}
    max_inference_context: ${rnn_inference_context}
    inference_context_step: ${rnn_inference_context_step}
  head_partial: ${head}
  loss:
    _target_: hotpp.losses.NHPLoss
    num_classes: ${num_classes}
    time_smoothing: ${time_smoothing}
    max_intensity: ${max_intensity}
    thinning_params: ${thinning_params}
  autoreg_max_steps: ${max_predictions}

trainer:
  precision: 32  # Prevent explosion.
